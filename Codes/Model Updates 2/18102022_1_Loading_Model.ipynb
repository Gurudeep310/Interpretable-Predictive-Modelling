{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Models for 3 Class Model"
      ],
      "metadata": {
        "id": "erBxVet-utO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from transformers import AutoTokenizer, TFBertModel "
      ],
      "metadata": {
        "id": "9VEGZX1VuzeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/My Folders/NLP_Research/bert_base_cased_basic_maslow_3_classifier.h5',custom_objects={'TFBertModel': TFBertModel})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk3mYAaLu2aW",
        "outputId": "dacce010-4df5-4158-dcd0-7312aa0c1bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wqY0AnXu5Zf",
        "outputId": "ae740194-9c54-463c-a8c3-19442eef085c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_3 (TFBertModel)  TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, None                                               \n",
            "                                , 768),                                                           \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 768)         0           ['tf_bert_model_3[0][0]']        \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          98432       ['global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_75 (Dropout)           (None, 128)          0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 32)           4128        ['dropout_75[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 3)            99          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,412,931\n",
            "Trainable params: 108,412,931\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "df = pd.read_csv('basic_advanced_reference.csv')\n",
        "df = df.iloc[0:10][:]\n",
        "df = df[['sentence','maslow']]\n",
        "counter = df.copy()\n",
        "counter['number_of_words'] = counter.sentence.apply(lambda x: len(x.split()))\n",
        "df = counter.copy()\n",
        "df['maslow'] = df.maslow.astype('category')\n",
        "df['maslow'] = df.maslow.cat.codes\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "bert = TFBertModel.from_pretrained('bert-base-cased')\n",
        "data_test = df.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeHu7Mbvu5x3",
        "outputId": "b9757a14-a99e-4694-a8ab-fb0c7df6a4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = tokenizer(\n",
        "    text = data_test.sentence.tolist(),\n",
        "    add_special_tokens = True,\n",
        "    max_length = None,\n",
        "    truncation = True,\n",
        "    padding = True, \n",
        "    return_tensors = 'tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True, \n",
        "    verbose = True\n",
        ")\n",
        "x_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sQf8M7jvKR-",
        "outputId": "9290641e-0d03-4d2e-e7d2-27d1b85f416f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(10, 52), dtype=int32, numpy=\n",
              "array([[  101,  9350,  1309, 10741,  4077,   119,  9350,  2795,  1146,\n",
              "         1114,  1123,  6508,  1105,  1245, 15941,   119,  1153,  1355,\n",
              "         1313,  1105,  1793,  5464,  4077,   119,   102,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [  101,  1109,  1266,  3416,   170, 12916,  1104,   175,  3377,\n",
              "          119,  1109,  1488,  8756,  1172,  1304,  2698,   119,  1109,\n",
              "         1797,  1400,  6340,   119,  4708,  1500,  1172,  1106,  1712,\n",
              "         1122,  1205,   119,   102,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [  101,  7312,  5005,  1408,  1280,  1106,  2842,  1278,   119,\n",
              "         1153,  1450,  1131,  1458,  1106,  2842,  1133,  1238,   112,\n",
              "          189,  1221,  1184,  1947,  1131, 18039,   119,  1258,   170,\n",
              "         1374,  2277,   117,  1131,  1108,  7820,  1206,  1160,   119,\n",
              "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [  101,  3458, 12179, 10435,  1144,   170,  2298,  1105,   170,\n",
              "         1873,  1107,  7876,  1278,   119, 11651,  1110,   130,  1105,\n",
              "         1889,  1110,   128,   119, 10435,  1163,  1889,  1110,  1640,\n",
              "         1515,  3819, 18761,   119,   102,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [  101,  3696,  1276,  1941,  3253, 11353,   119,  1153,  1464,\n",
              "         1115,  1131,  1508,  1177,  1277,  3098,  1154,  1123,  2261,\n",
              "          119,  3696,  1309,  1180,  1243,  1103,  4453,  1131, 10796,\n",
              "          119,  1153,  1408,  1833,  1750,  1105,  1750,  1250,   119,\n",
              "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [  101,  7133,  1458,  1106,  1686,  6695,  1714,   119,  1124,\n",
              "         1253, 12390,   170,  1974,  1104,  1948,  1113,  1117, 16935,\n",
              "          119,  1124,  1408,  7740,  1948,  1107,  1103,  3085,   119,\n",
              "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [  101,  4446,  1108,  1120,  1103,  4528,  1114,  1117,  2053,\n",
              "          119,  1220,  1127,  1155, 16358, 25351,  1213,   119,  6518,\n",
              "         2873,  4446,  1154,  1103,  4528,   119,  1124,  1855,  1117,\n",
              "         1246,  1113,  1103,  2652,   119,  1220,  1127,  1682,  1106,\n",
              "         1243,  1140,  1149,  1198,  1107,  1159,   119,   102,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [  101,  3379,  1105,  1117,  6124,  1138,  1151,  1487,  1111,\n",
              "          126,  1201,   119,   102,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [  101,   146,  1400,   170,  1632, 20538,  1111,  9323,  1228,\n",
              "         1103,  7210,   119,   146,  1408,  8739,  1105,  1122,  1350,\n",
              "         1632,  1105,  9317, 13108,   119,   102,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [  101,  9300,   112,   188,  2153,  1309,  5029,  1164,  1948,\n",
              "         1107,  1524,  1104,  1147,  1488,   119,  1124,  1767,  1199,\n",
              "         4067,  1120,  1278, 12418, 10932,  1164,  1147,  4153,  1116,\n",
              "          112, 23343,   119,  1109,  4067,  1455,  9300,  1293,  1277,\n",
              "         1948,  1117,  4153,  1189,   119,  9300,  3028,  1114,   170,\n",
              "         7584,  1119,  1354,  4234,  7757,   119,   102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(10, 52), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_raw = new_model.predict({'input_ids': x_test['input_ids'], 'attention_mask': x_test['attention_mask']}) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8h87nUQvOVn",
        "outputId": "ede63054-5a00-408c-fce8-3fea3ffcf635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "y_predicted = np.argmax(predicted_raw, axis = 1)"
      ],
      "metadata": {
        "id": "dFcs2hkPvUMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XlOM-i-vqyZ",
        "outputId": "35c94d3f-8eda-42d0-8d85-13c09239ed79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 2, 2, 2, 0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n8yQpXqevsS8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}